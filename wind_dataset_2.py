# -*- coding: utf-8 -*-
"""wind  dataset 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10w6bOnUsqN7RJg_UgApPprzJTLxo5jsi
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('/content/drive/MyDrive/Data science/CSVS/T1.csv')

data

data.drop('Date/Time',axis=1,inplace=True)
data

data.corr()

#heatmap
import seaborn as sns
sns.heatmap(data.corr())

#scatter plot
plt.scatter(data['Wind Direction (째)'],data['Theoretical_Power_Curve (KWh)'])
plt.title("Numerical Feature: Theoretical_Power_Curve (KWh) v/s wind direction")
plt.xlabel("Wind Direction (째)")
plt.ylabel("Theoretical_Power_Curve (KWh)")

plt.scatter(data['Wind Speed (m/s)'],data['Theoretical_Power_Curve (KWh)'],color='y')
plt.title("Numerical Feature:  Theoretical_Power_Curve (KWh)  v/s windspeed")
plt.xlabel("windspeed")
plt.ylabel("Theoretical_Power_Curve (KWh)")

plt.scatter(data['LV ActivePower (kW)'],data['Theoretical_Power_Curve (KWh)'],color='r')
plt.title("Numerical Feature: Theoretical_power vs LV ActivePower(KW)  Th")
plt.xlabel("LV ActivePower ")
plt.ylabel("Theoretical power")

"""## **as we can see both the feature 'LV ActivePower (kW)' and 'Theoretical_Power_Curve (KWh)' have similar distribution and may present redundancy and even multicollinearity. to keep things clean we can drop the 'LV ActivePower (kW)' feature**"""

#joint plot
sns.jointplot(data['LV ActivePower (kW)'],data['Theoretical_Power_Curve (KWh)'])

sns.jointplot(data['Wind Speed (m/s)'],data['Theoretical_Power_Curve (KWh)'], height=6, ratio=5, space=0.2)

sns.jointplot(data['Wind Direction (째)'],data['Theoretical_Power_Curve (KWh)'])

#line plots
plt.plot(data['Wind Direction (째)'],data['Theoretical_Power_Curve (KWh)'],'g')
plt.xlabel("wind direction")
plt.ylabel("Theoretical_Power_Curve (KWh)")

plt.plot(data['Wind Speed (m/s)'],data['Theoretical_Power_Curve (KWh)'])
plt.xlabel("wind speed")
plt.ylabel("Theoretical_Power_Curve (KWh)")

plt.plot(data['LV ActivePower (kW)'],data['Theoretical_Power_Curve (KWh)'])
plt.xlabel("LV ActivePower")
plt.ylabel("Theoretical power")

#taking care of missing data
data.isnull().any()

"""# *no missing data*"""

#separating dependent and independent variables
data1=data.drop('Theoretical_Power_Curve (KWh)',axis=1)
x=data1.iloc[0:,0:3].values
x

y=data.iloc[0:,2].values
y

#label encoding and # onehot encoding

"""## **as there are no categorical coloumns..there is no need to do label encoding and one hot encoding**"""

#feature scaling
from sklearn.preprocessing import MinMaxScaler
m=MinMaxScaler()
x=m.fit_transform(x)
print("after minmax scaling")
x

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x=sc.fit_transform(x)
print("after standard scaling")
x

from joblib import dump
dump(sc,"scalar2.save")

#splitting train and test data
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

x_train

y_train

x_test

y_test

"""## **model building**"""

plt.scatter(x[:,1],y)

plt.scatter(x[:,2],y)

plt.scatter(x[:,0],y)

"""# **from above observations multilinear fits this dataset..as the column contains continues values**"""

from sklearn.linear_model import LinearRegression
mr=LinearRegression()
mr.fit(x_train,y_train)

import pickle
pickle.dump(mr,open('decision2.pkl','wb'))

y_pred=mr.predict(x_test)

y_pred

y_test

#model evaluation
from sklearn.metrics import r2_score
r2_score(y_pred,y_test)